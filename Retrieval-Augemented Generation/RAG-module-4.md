# RAG Module 4: LLMs and Text Generation

## Learning Objectives

- Explain the components of a transformer and how they impact the operation of an LLM inside a RAG system  
- Choose the appropriate LLM for a project based on qualities like cost, context window, knowledge cutoff, and performance on LLM benchmarks  
- Explain the operation of techniques including LLM sampling strategies, prompt engineering, and hallucination detection, and evaluate how best to use these techniques inside a RAG system  
- Identify the benefits of agentic workflows or fine-tuned LLMs and assess when they could be used to improve the performance of a RAG system  
- Build a RAG system that uses a variety of advanced techniques to improve the quality of an LLM's performance  

## Introduction

## Transformer Architecture

- Why RAG Works  
  - Attention mechanism processing  
  - World knowledge in feed forward layers  
  
- Inherent randomness remains  
  - LLMs may rtandomly inject information  
  - Need to control randomnes  
  - Must confirm LLMs ground info in retrieved information  
    
- Computational Expenses  
  - Generating single tokens requires extensive processing  
  - Costs grow with prompt/completion graph  
  - Each token must examine all other for content  
  - Most RAG system costs come from running transformers   
  
## LLM Sampling Strategies

- Every token generated by a weighted random choice  
- Peaked distribution model is "confident"  
- Flat distribution model is "uncertain"  
  
Decoding Strategies  
- **Greedy decoding**  
  - Always pick token with highest probability  
  - Deterministic  
  - Generic-sounding  
  - Can get stuck in a loop  
  - Useful in code completion or debugging  
- **Temperature**  
  - Changes the shpae of the distribution of tokens  
  - Temperature of 0 ==> Greedy decoding  
    - Deterministic  
    - One token has 100% probability  
    - Same output given same prompt  
  - Temperature of 5 ==> Flat distribution   
    - Generates nonsense  
    - All tokens have equal probability  
 - **Advanced Token Sampling**  
   - Top-K Sampling  
     - Picks from the top K most likely tokens  
	 - Can be combined with temperature  
   - Top-P Sampling  
     - Pick from tokens whose cummalative probability is below some threshold  
 - **Token Specific Strategies**  
     - Repetition penalties  
	 - Helps prevent: Loops, Redundant phrases, Overuse of specific words  
	 - Logit biases  
	   - Direct manipulation of token probabilities  
	   - Can add or subtract from the values  
	     - Profanity: Severely lower probability of those words  
	     - Classifier: Significantly boost probability of each class  
    
  
## Exploring LLM Capabilities (LAB)

- temperature  
- top-K  
- top-P  
  
## Choosing Your LLM  
  
LLM Characteristics  
- Model Size  
  - Small models: 1-100 billion parameters  
  - Largel models: 100-500 billion parameters  
  - Large models can be more capable, always more expesnsive  
- Cost  
  - Fixed cost per millions of tokens  
  - New and larger moodels usually cost more  
  - Different pricing for inpput vs output tokens  
- Context window  
  - Maximmum number of tokens split between prompt & output  
  - Still pay per token  
- Latency and speed  
  - Time to first token  
  - Tokens per second  
- Training cutoff date  
  - Last point in time of models training data  
  - Later is usually preferable  
  
LLM Quality Metrics  
  - Much harder to quantify  
  - Many types of quality  
  - Numerous benchmarks that attempt to measure qualioty  
  - No single authoratative list of benchmarks  
    
Three types of benchmarks  
   - Automated  
   - Human scoring  
   - LLM as a judge  
     
## Prompt Engineering: Building Your Augmented Prompt  
  
Messages format  
- Role  
  - System  
  - User  
  - Assistant  
  
Message turns  
  - Previous messages are not remembered  
  - Passed in to the next prompt  
    
System Prompt  
  - Provides high lervel instructions  
  - Includes desired tone  
  - Includes procedures LLM should follow  
  - Are included in every query processed  
    
Principles for constructring system prompt  
  - Instruct about response  
    - E.g "Povide great detail"  
    - Or "Answer questions succinctly"  
  - For RAG cases  
    - Instruct model to only use context  
	- Instruct model to judge relevancy  
	- Instruct the model to cite sources  
    
Prompt Templates  
  - System Instructions  
  - Conversation History  
  - Retrieved Documents  
  - Current Query  
    
  
## Prompt Engineering: Advanced Techniques  
  
- In Context Learning  
  - One shot learning  
  - Few shot learning  
  - Can implement in different ways  
    1. by hardcoding examples  
    2. using RAG to retieve question/answer pairs  
	  
- Encouraging reasoning  
  - Think step-by-step  
  - Scratchpad technique  
    
- Chain of Thought prompting  
   - Very succesful  
   - Gave rise to Reasoning Models  
   - Distinguish reasoning and response tokens  
     
- Reasopning Models  
  - Reasoning tokens improve accuracy but add cost  
  - Models are slower and more expensive  
  - Can be worth it in RAG because excel at relevance  
  - Some prompt techniques don't work with resoning models  
	- Struggle with in context learning and examples  
    - Perform best when given clear goals and strict formats  
	- Work well with full context and high-level guidance  
  - LLM prsdoviders frequently release new models  
  - LLM providers provide prompting guidelines  
	  
- Context Window Management  
  - With Reasoning Mopdel + RAG  
	- Initial prompt  
    - Reasoning tokens  
    - RAG documents  
    - Response tokens  
  - Easy to fill up context window  
  - Management Strategies  
    - Single-Turn  
	  - Skip prompt techniques that don't add value  
	- Multi-turn  
	  - Use fixed size history or prune appropriately  
	  - Use LLM to summarize chat history   
	- Use long-context models for deeper multi-turn conversations  
	- Even with big context keep prompts efficient  
	  
- Only use advanced techniques when it is clear they are needed  
  
## Handling Hallucinations  
  
- Even the best LLMs hallucinate  
- Why LLMs Hallucinate  
  - LLMs produce probable text sequences  
  - Probable text not accurate  
	- LLMs do not distinguish true and false  
- Why hallucinations matter  
  - Inaccurated info  
  - Hard to detect  
  - Erode trust  
  - RAG can help: grounds responses in reliable knowledge  
- Types of hallucinations  
  - Mess up small details  
  - Entirely invent facts  
  - Need to evaluate output of many levels  
- Currently no perfect solution for hallucinations  
  - RAG isd actuially one of the best approaches  
    
- Self-Consistency Methods  
  - Repeatedly generate responses to same prompt  
  - Inconsistencies often indicate hallucination  
  - Inpractive costly and unreliable  
    
- Reducing Hallucinations with RAG  
  - Grounding responses in RAG documednts  
  - Citation generation  
  - LLMs can hallucinate citations  
    
- External Verification Sites  
  - ContextCite  
    
- Evaluating Citation Quyality in LLMs   
  - ALCE Benchmark  
  - Pre-assembled knowledge base + Questions  
  - Tests RAG system responses on prepared prompts  
  - Evaluates across three Key Evaluation Metrics  
    - **Fluency**  
	- **Correctness**  
	- **Citation Quality**  
	
## Evaluating your LLM's performance

Ragas Library
- **Response Relevancy Metric**
  - Doesn't check for factual accuracy
  - Generates several "sample prompts that could lead to answer
  - Embeds prompts and averages cosine similarity wrt original prompt
- **Faithfullness Metric**
  - Measures if response is consistent with retrieved info
  - LLM identifies all factual claims
  - LLM determinews if claims are supported by retrieved docs
  - Return percentage of supported claims
- **Other Metrics**
  - Citations
  - Factuality
  - All metrics use LLM-as-a-Judge at some point
  - Some degree of subjectivity
  - Can also have users eval some sample of response
    - Allows for system-wide assessment
	- Can then perform mA/B tests to adjust LLM parameters
	- Can indicate when to switch to another model
Summary
    - Should use LLM-as-a-Judge or Human feedback to evaluate
	- A combination of both will allow accurate assessment of performance
	
	
## Agentic RAG

- Workiflows
  - Sequential workflows
  - Conditional workflows
  - Iterative workflows
  - Parallel workflows
  
- Conceptual Shift
  - In Agentic RAG LLMs no longer standalone solution
  - They are a modular part of a complex system
  
## Agentic RAG vs. Fine-Tune

- Understanding Fine-Tuning
  - Idea is to retrain an LLM with your own data
  - Performed using Supervised Fine-Tuning (SFT)
    - Retrains model with labeled examples
	- Instruction tuning teaches task following instructions
- Fine-Tuning Example
  - Medical Industry
    - Generalist model will give a non-medical response
	- Before SFT we get a general high level answer
	- After SFT we get a precise medical answer
- When SFT woirks well
  - Only optimizes model in a spefcific domain
  - Can decrease model performance in other domains
  
- RAG vs. Fine-Tuning
  - RAG excels in knowledgfe ingestion
  - SFT excels at domain adaptation
  - Sometimes best choice is both
  
- Gettingf started with SFT
  - Take a course or use pre-tuned model
  - Hard topic and complex technique

- RAG & SFT are complementary rather than competing techniques

## Conclusion

Tranformer Architecture
Sampling Strategies
Model Selection & Prompting
Performance E$valuastion
Advanced Capabilities
  - Supervised Fine-Tuning
  - Agentic AI
